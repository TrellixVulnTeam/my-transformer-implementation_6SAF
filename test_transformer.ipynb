{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10c0bf9d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key tranpsoed shape:  torch.Size([256, 3, 21])\n",
      "query shape:  torch.Size([256, 25, 3])\n",
      "attn_output_weights shape  torch.Size([256, 25, 21])\n",
      "attn_output_weights shape after softmax torch.Size([256, 25, 21])\n",
      "torch.Size([25, 256, 3]) torch.Size([256, 25, 21])\n"
     ]
    }
   ],
   "source": [
    "SDP = torchtext.nn.ScaledDotProduct(dropout=0.1)\n",
    "q = torch.randn(25, 256, 3)\n",
    "k = v = torch.randn(21, 256, 3)\n",
    "expected_attn_output, expected_attn_weights = SDP(q, k, v)\n",
    "print(expected_attn_output.shape, expected_attn_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertEqual(t1, t2):\n",
    "    assert torch.eq(t1, t2).all()\n",
    "    print(\"passed assertEqual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_head corresponds to d_k in the paper\n",
    "def scaled_dot_product_attention(value, key, query, dropout=0.1):\n",
    "    \"\"\"\n",
    "    Shape:\n",
    "    - query: `(..., T, N * H, E / H)`\n",
    "    - key: `(..., S, N * H, E / H)`\n",
    "    - value: `(..., S, N * H, E /H)`\n",
    "    \n",
    "    where E = d_model, E/H = d_head\n",
    "    \"\"\"\n",
    "    assertEqual(value, v)\n",
    "    assertEqual(key, k)\n",
    "    assertEqual(query, q)\n",
    "    \n",
    "    assert query.shape[-1] == key.shape[-1] == value.shape[-1], \"The d_head of query, key, value must be equal.\"\n",
    "    S, T, N_H, d_head = key.shape[-3], query.shape[-3], query.shape[-2], query.shape[-1]\n",
    "    \n",
    "    query, key, value = query.transpose(-2, -3), key.transpose(-2, -3), value.transpose(-2, -3)\n",
    "\n",
    "    # calculates attention weights\n",
    "    query = query * (float(d_head) ** -0.5)     \n",
    "    attention_weights = torch.matmul(query, key.transpose(-2,-1))\n",
    "    attention_weights = torch.nn.functional.softmax(attention_weights, dim=-1)\n",
    "    attention_weights = torch.nn.functional.dropout(attention_weights, p=dropout)\n",
    "    assert attention_weights.shape == (N_H, T, S), \"attention_weights should be shape (N * H, T, S)\"\n",
    "\n",
    "    attention_output = torch.matmul(attention_weights, value)\n",
    "\n",
    "    return attention_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed assertEqual\n",
      "passed assertEqual\n",
      "passed assertEqual\n"
     ]
    }
   ],
   "source": [
    "attn_output, attn_weights = scaled_dot_product_attention(v, k, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[7.3709e-03, 1.0526e-02, 3.1706e-01,  ..., 5.3871e-02,\n",
      "          1.4450e-01, 9.8899e-03],\n",
      "         [5.2474e-03, 7.2790e-04, 2.1213e-03,  ..., 2.7348e-03,\n",
      "          3.3701e-03, 2.1130e-01],\n",
      "         [7.9056e-02, 6.6726e-02, 1.3913e-02,  ..., 2.6752e-02,\n",
      "          0.0000e+00, 5.7255e-02],\n",
      "         ...,\n",
      "         [3.2884e-02, 1.1404e-01, 1.7159e-01,  ..., 1.3734e-01,\n",
      "          1.1767e-01, 0.0000e+00],\n",
      "         [3.5993e-03, 3.5142e-03, 1.2023e-02,  ..., 4.5520e-02,\n",
      "          1.6123e-02, 5.1409e-02],\n",
      "         [4.2352e-02, 2.2713e-02, 4.4686e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 7.4061e-02]],\n",
      "\n",
      "        [[1.8031e-03, 6.8657e-02, 2.0406e-01,  ..., 4.0332e-02,\n",
      "          2.1923e-02, 4.4464e-03],\n",
      "         [1.4574e-02, 7.4297e-02, 2.1377e-01,  ..., 5.6560e-02,\n",
      "          1.1533e-02, 2.0428e-02],\n",
      "         [0.0000e+00, 4.8970e-02, 6.1474e-02,  ..., 6.9460e-02,\n",
      "          2.2376e-02, 6.1622e-02],\n",
      "         ...,\n",
      "         [3.2817e-02, 3.7500e-02, 1.7899e-02,  ..., 2.8935e-02,\n",
      "          3.1883e-01, 2.2932e-02],\n",
      "         [1.5836e-02, 7.7541e-02, 2.0358e-01,  ..., 3.5738e-02,\n",
      "          2.6582e-02, 9.3830e-03],\n",
      "         [1.9428e-02, 7.4771e-02, 1.0671e-01,  ..., 5.9182e-02,\n",
      "          5.7442e-02, 2.5529e-02]],\n",
      "\n",
      "        [[2.8087e-02, 9.3863e-02, 6.2261e-02,  ..., 5.2177e-02,\n",
      "          4.1302e-02, 8.4354e-03],\n",
      "         [0.0000e+00, 4.3815e-02, 2.0317e-02,  ..., 5.7210e-02,\n",
      "          3.4688e-02, 3.8777e-02],\n",
      "         [1.2270e-02, 5.0945e-02, 1.8476e-02,  ..., 2.2935e-02,\n",
      "          6.2460e-03, 7.7826e-04],\n",
      "         ...,\n",
      "         [2.1374e-02, 2.8422e-02, 1.0053e-01,  ..., 0.0000e+00,\n",
      "          2.4591e-02, 9.8160e-02],\n",
      "         [1.2963e-02, 3.8105e-02, 2.9656e-01,  ..., 2.8760e-02,\n",
      "          4.9832e-03, 4.9936e-02],\n",
      "         [1.7570e-02, 8.5651e-02, 1.3087e-01,  ..., 4.5523e-02,\n",
      "          5.4494e-02, 1.8253e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[5.2150e-01, 7.2931e-03, 1.4155e-02,  ..., 3.7012e-04,\n",
      "          5.8628e-02, 1.8267e-02],\n",
      "         [2.1577e-01, 3.1065e-02, 3.2988e-02,  ..., 1.8068e-02,\n",
      "          0.0000e+00, 2.1756e-01],\n",
      "         [5.5330e-01, 9.5128e-03, 1.3975e-02,  ..., 2.5697e-03,\n",
      "          1.7911e-02, 0.0000e+00],\n",
      "         ...,\n",
      "         [2.4414e-02, 1.9288e-02, 3.4944e-02,  ..., 1.6291e-02,\n",
      "          5.5178e-02, 5.8803e-03],\n",
      "         [2.9861e-03, 2.9434e-02, 2.7196e-02,  ..., 2.2408e-01,\n",
      "          1.1729e-02, 0.0000e+00],\n",
      "         [6.7230e-02, 0.0000e+00, 5.3535e-02,  ..., 3.6841e-02,\n",
      "          6.3375e-02, 4.3952e-02]],\n",
      "\n",
      "        [[6.7194e-02, 3.6061e-02, 1.7001e-02,  ..., 3.2367e-02,\n",
      "          3.1291e-02, 9.7230e-03],\n",
      "         [6.0031e-04, 6.6566e-02, 6.6827e-02,  ..., 2.4884e-02,\n",
      "          9.6894e-03, 2.8376e-01],\n",
      "         [6.2977e-02, 3.9457e-02, 5.5688e-02,  ..., 7.0306e-02,\n",
      "          0.0000e+00, 4.9014e-02],\n",
      "         ...,\n",
      "         [1.8137e-01, 2.1715e-02, 1.5099e-02,  ..., 2.2330e-02,\n",
      "          0.0000e+00, 7.4632e-03],\n",
      "         [1.1723e-02, 1.2095e-01, 5.3594e-02,  ..., 3.6750e-02,\n",
      "          3.5384e-02, 8.8456e-02],\n",
      "         [5.7980e-02, 2.3565e-02, 4.4763e-02,  ..., 3.6233e-02,\n",
      "          4.7171e-02, 4.5756e-02]],\n",
      "\n",
      "        [[1.5446e-02, 4.8991e-02, 6.1911e-02,  ..., 1.3527e-02,\n",
      "          2.7604e-02, 3.3996e-02],\n",
      "         [4.6849e-02, 3.0040e-02, 1.4816e-01,  ..., 9.6605e-03,\n",
      "          1.3918e-02, 4.0383e-02],\n",
      "         [3.3363e-02, 2.6639e-02, 1.7860e-01,  ..., 2.2251e-02,\n",
      "          8.0952e-03, 0.0000e+00],\n",
      "         ...,\n",
      "         [1.0554e-02, 4.6476e-02, 1.0179e-02,  ..., 3.2635e-01,\n",
      "          5.2962e-02, 3.2407e-02],\n",
      "         [4.0203e-02, 4.4353e-02, 1.1120e-01,  ..., 3.1954e-02,\n",
      "          2.3200e-02, 5.1491e-02],\n",
      "         [4.4157e-02, 5.6728e-02, 0.0000e+00,  ..., 1.0518e-01,\n",
      "          0.0000e+00, 5.1762e-02]]])\n"
     ]
    }
   ],
   "source": [
    "print(expected_attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[7.3709e-03, 1.0526e-02, 3.1706e-01,  ..., 5.3871e-02,\n",
      "          1.4450e-01, 9.8899e-03],\n",
      "         [5.2474e-03, 7.2790e-04, 2.1213e-03,  ..., 2.7348e-03,\n",
      "          3.3701e-03, 2.1130e-01],\n",
      "         [7.9056e-02, 6.6726e-02, 1.3913e-02,  ..., 0.0000e+00,\n",
      "          1.9131e-02, 5.7255e-02],\n",
      "         ...,\n",
      "         [3.2884e-02, 1.1404e-01, 1.7159e-01,  ..., 1.3734e-01,\n",
      "          1.1767e-01, 7.4021e-03],\n",
      "         [3.5993e-03, 3.5142e-03, 1.2023e-02,  ..., 4.5520e-02,\n",
      "          1.6123e-02, 5.1409e-02],\n",
      "         [4.2352e-02, 2.2713e-02, 4.4686e-02,  ..., 2.2976e-02,\n",
      "          4.1240e-02, 0.0000e+00]],\n",
      "\n",
      "        [[1.8031e-03, 6.8657e-02, 2.0406e-01,  ..., 0.0000e+00,\n",
      "          2.1923e-02, 0.0000e+00],\n",
      "         [1.4574e-02, 7.4297e-02, 2.1377e-01,  ..., 5.6560e-02,\n",
      "          1.1533e-02, 2.0428e-02],\n",
      "         [2.4224e-02, 4.8970e-02, 6.1474e-02,  ..., 6.9460e-02,\n",
      "          2.2376e-02, 6.1622e-02],\n",
      "         ...,\n",
      "         [3.2817e-02, 3.7500e-02, 1.7899e-02,  ..., 2.8935e-02,\n",
      "          3.1883e-01, 2.2932e-02],\n",
      "         [1.5836e-02, 7.7541e-02, 2.0358e-01,  ..., 3.5738e-02,\n",
      "          2.6582e-02, 9.3830e-03],\n",
      "         [1.9428e-02, 7.4771e-02, 1.0671e-01,  ..., 5.9182e-02,\n",
      "          5.7442e-02, 2.5529e-02]],\n",
      "\n",
      "        [[2.8087e-02, 9.3863e-02, 6.2261e-02,  ..., 5.2177e-02,\n",
      "          4.1302e-02, 8.4354e-03],\n",
      "         [1.0503e-01, 4.3815e-02, 2.0317e-02,  ..., 5.7210e-02,\n",
      "          3.4688e-02, 3.8777e-02],\n",
      "         [1.2270e-02, 5.0945e-02, 1.8476e-02,  ..., 2.2935e-02,\n",
      "          6.2460e-03, 7.7826e-04],\n",
      "         ...,\n",
      "         [2.1374e-02, 2.8422e-02, 0.0000e+00,  ..., 2.9195e-02,\n",
      "          2.4591e-02, 9.8160e-02],\n",
      "         [1.2963e-02, 3.8105e-02, 2.9656e-01,  ..., 2.8760e-02,\n",
      "          4.9832e-03, 4.9936e-02],\n",
      "         [1.7570e-02, 8.5651e-02, 0.0000e+00,  ..., 4.5523e-02,\n",
      "          5.4494e-02, 0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[5.2150e-01, 7.2931e-03, 1.4155e-02,  ..., 3.7012e-04,\n",
      "          5.8628e-02, 1.8267e-02],\n",
      "         [2.1577e-01, 3.1065e-02, 3.2988e-02,  ..., 1.8068e-02,\n",
      "          3.2484e-02, 2.1756e-01],\n",
      "         [5.5330e-01, 9.5128e-03, 1.3975e-02,  ..., 2.5697e-03,\n",
      "          1.7911e-02, 2.5690e-01],\n",
      "         ...,\n",
      "         [2.4414e-02, 0.0000e+00, 3.4944e-02,  ..., 1.6291e-02,\n",
      "          5.5178e-02, 5.8803e-03],\n",
      "         [2.9861e-03, 2.9434e-02, 2.7196e-02,  ..., 2.2408e-01,\n",
      "          1.1729e-02, 1.6617e-02],\n",
      "         [6.7230e-02, 4.8098e-02, 0.0000e+00,  ..., 3.6841e-02,\n",
      "          6.3375e-02, 4.3952e-02]],\n",
      "\n",
      "        [[6.7194e-02, 3.6061e-02, 1.7001e-02,  ..., 3.2367e-02,\n",
      "          3.1291e-02, 9.7230e-03],\n",
      "         [0.0000e+00, 6.6566e-02, 6.6827e-02,  ..., 0.0000e+00,\n",
      "          9.6894e-03, 2.8376e-01],\n",
      "         [6.2977e-02, 3.9457e-02, 5.5688e-02,  ..., 0.0000e+00,\n",
      "          5.0304e-02, 4.9014e-02],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 1.5099e-02,  ..., 2.2330e-02,\n",
      "          4.7556e-02, 7.4632e-03],\n",
      "         [1.1723e-02, 1.2095e-01, 5.3594e-02,  ..., 3.6750e-02,\n",
      "          3.5384e-02, 8.8456e-02],\n",
      "         [5.7980e-02, 2.3565e-02, 4.4763e-02,  ..., 3.6233e-02,\n",
      "          4.7171e-02, 4.5756e-02]],\n",
      "\n",
      "        [[0.0000e+00, 4.8991e-02, 6.1911e-02,  ..., 1.3527e-02,\n",
      "          2.7604e-02, 3.3996e-02],\n",
      "         [4.6849e-02, 3.0040e-02, 1.4816e-01,  ..., 9.6605e-03,\n",
      "          1.3918e-02, 0.0000e+00],\n",
      "         [3.3363e-02, 2.6639e-02, 1.7860e-01,  ..., 2.2251e-02,\n",
      "          8.0952e-03, 4.2551e-02],\n",
      "         ...,\n",
      "         [1.0554e-02, 4.6476e-02, 1.0179e-02,  ..., 3.2635e-01,\n",
      "          5.2962e-02, 3.2407e-02],\n",
      "         [4.0203e-02, 4.4353e-02, 1.1120e-01,  ..., 3.1954e-02,\n",
      "          2.3200e-02, 5.1491e-02],\n",
      "         [4.4157e-02, 5.6728e-02, 3.2138e-02,  ..., 1.0518e-01,\n",
      "          6.9742e-02, 5.1762e-02]]])\n"
     ]
    }
   ],
   "source": [
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-749c21c756ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected_attn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0massertEqual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_attn_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-67dedae87982>\u001b[0m in \u001b[0;36massertEqual\u001b[0;34m(t1, t2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0massertEqual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"passed assertEqual\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert attn_weights.shape == expected_attn_weights.shape\n",
    "assertEqual(attn_weights, expected_attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 25, 3]) torch.Size([256, 25, 21])\n"
     ]
    }
   ],
   "source": [
    "print(attn_output.shape, attn_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_attn_output:  tensor([[[-1.7754e-01,  1.2924e-01,  1.5124e-01],\n",
      "         [-5.5349e-01,  9.9234e-02, -1.0563e-01],\n",
      "         [-9.8998e-01,  4.5181e-03, -6.7981e-01],\n",
      "         ...,\n",
      "         [-8.1611e-01,  8.0464e-01,  1.4902e+00],\n",
      "         [ 1.2824e+00,  1.1947e+00,  3.6544e-01],\n",
      "         [ 1.7662e-01, -8.4852e-01, -2.9297e-01]],\n",
      "\n",
      "        [[ 7.8802e-01, -8.1057e-01,  4.0439e-01],\n",
      "         [-1.0824e+00, -9.2882e-01, -2.4140e-01],\n",
      "         [-2.5309e+00, -1.5416e+00, -4.3882e-01],\n",
      "         ...,\n",
      "         [-4.3796e-01,  8.1887e-01, -2.4539e-01],\n",
      "         [-1.0819e+00, -2.4269e-01,  1.4391e-01],\n",
      "         [ 3.8632e-01,  2.7089e-01, -3.7836e-01]],\n",
      "\n",
      "        [[ 5.2584e-01,  2.4597e-01,  6.9702e-01],\n",
      "         [-3.9866e-01,  9.3980e-01,  2.9205e-01],\n",
      "         [-1.1475e+00, -8.7214e-01, -4.5471e-01],\n",
      "         ...,\n",
      "         [-8.9404e-01,  1.0199e+00,  1.6401e+00],\n",
      "         [ 2.2478e-01, -5.7274e-01, -2.8966e-01],\n",
      "         [ 7.0868e-01,  6.0373e-01, -8.6544e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 9.8660e-01,  5.9443e-02,  5.0102e-01],\n",
      "         [-1.4668e-01,  3.2919e-02, -2.4189e-01],\n",
      "         [-5.0950e-02,  9.0109e-01, -5.9361e-01],\n",
      "         ...,\n",
      "         [-4.0603e-02, -1.4799e+00,  7.5744e-01],\n",
      "         [ 3.1427e-01,  2.1402e-01,  1.2638e-02],\n",
      "         [ 3.4644e-01,  1.5828e-01, -1.1328e-01]],\n",
      "\n",
      "        [[-3.5321e-01,  5.9409e-01,  1.4041e-01],\n",
      "         [-3.1410e-01, -9.2106e-02, -3.5490e-01],\n",
      "         [-1.9764e+00, -5.9559e-01,  4.1114e-01],\n",
      "         ...,\n",
      "         [ 2.5406e-03, -7.2940e-01,  3.5636e-01],\n",
      "         [-1.5226e-01, -3.9985e-01,  5.5804e-01],\n",
      "         [ 4.7753e-01,  1.3460e-01, -3.7501e-01]],\n",
      "\n",
      "        [[ 1.1352e+00, -6.4898e-01,  1.0014e+00],\n",
      "         [-7.2449e-01,  4.4066e-01,  1.3378e+00],\n",
      "         [ 6.6798e-05, -5.6496e-01,  3.3559e-01],\n",
      "         ...,\n",
      "         [-1.0156e+00,  5.0984e-01,  8.8403e-02],\n",
      "         [-3.6617e-02, -4.0805e-01,  1.9858e-01],\n",
      "         [ 4.9719e-02,  2.3583e-02,  1.7987e-01]]])\n",
      "actual_attn_output:  tensor([[[-1.5769e-01,  1.7620e-01,  1.9757e-01],\n",
      "         [ 6.8262e-01, -7.3752e-01,  3.4271e-01],\n",
      "         [ 4.5894e-01,  2.1706e-01,  6.1588e-01],\n",
      "         ...,\n",
      "         [ 8.8760e-01,  5.4498e-02,  4.6639e-01],\n",
      "         [-3.1363e-01,  5.2316e-01,  1.3629e-01],\n",
      "         [ 1.0198e+00, -5.7854e-01,  9.0540e-01]],\n",
      "\n",
      "        [[-5.5801e-01,  1.8307e-01, -2.2990e-01],\n",
      "         [-9.4285e-01, -8.5937e-01, -2.0123e-01],\n",
      "         [-3.2437e-01,  8.5772e-01,  2.5506e-01],\n",
      "         ...,\n",
      "         [-1.0357e-01,  1.4599e-01, -1.4603e-01],\n",
      "         [-3.4496e-01,  6.3663e-02, -5.3441e-01],\n",
      "         [-6.3139e-01,  4.4334e-01,  1.2076e+00]],\n",
      "\n",
      "        [[-8.9075e-01,  1.3495e-03, -6.0306e-01],\n",
      "         [-2.2819e+00, -1.4223e+00, -4.1409e-01],\n",
      "         [-1.0326e+00, -8.7607e-01, -4.8526e-01],\n",
      "         ...,\n",
      "         [ 4.8249e-02,  8.7924e-01, -5.8436e-01],\n",
      "         [-1.7805e+00, -5.4449e-01,  3.6702e-01],\n",
      "         [-2.4430e-02, -7.9426e-01,  2.3827e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-7.3658e-01,  7.1743e-01,  1.3372e+00],\n",
      "         [-4.7961e-01,  7.9594e-01, -3.6381e-01],\n",
      "         [-8.2785e-01,  8.9966e-01,  1.4726e+00],\n",
      "         ...,\n",
      "         [-3.6543e-02, -1.3319e+00,  6.8169e-01],\n",
      "         [-5.4839e-04, -7.0191e-01,  3.5285e-01],\n",
      "         [-9.0066e-01,  4.1018e-01,  7.9962e-02]],\n",
      "\n",
      "        [[ 1.1532e+00,  1.0688e+00,  3.2413e-01],\n",
      "         [-9.9758e-01, -2.6992e-01,  1.9075e-01],\n",
      "         [ 3.1020e-01, -5.6285e-01, -2.4029e-01],\n",
      "         ...,\n",
      "         [ 2.6150e-01,  1.7304e-01,  7.8235e-04],\n",
      "         [-7.4922e-02, -4.5632e-01,  4.6279e-01],\n",
      "         [ 3.7373e-01, -1.0130e+00,  2.3698e-01]],\n",
      "\n",
      "        [[ 1.5896e-01, -7.6367e-01, -2.6368e-01],\n",
      "         [ 3.0717e-01,  2.0489e-01, -3.3208e-01],\n",
      "         [ 6.3781e-01,  5.4336e-01, -7.7890e-02],\n",
      "         ...,\n",
      "         [ 4.5020e-01,  9.8148e-02, -1.8255e-01],\n",
      "         [ 5.1148e-01,  1.2701e-01, -3.1222e-01],\n",
      "         [-5.5680e-03, -7.6930e-02,  5.6534e-02]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"expected_attn_output: \", expected_attn_output)\n",
    "print(\"actual_attn_output: \", attn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (25) must match the size of tensor b (256) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-263db250d048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexpected_attn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (25) must match the size of tensor b (256) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "assert(torch.eq(attn_output,expected_attn_output).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
